# -*- coding: utf-8 -*-
"""Data Science Jobs in India EDA - Naukri.com.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F5c3y9dgT8Ub0xd23erRTvvH0KpRps7w
"""

# Commented out IPython magic to ensure Python compatibility.
# import libraries
import re
import pandas as pd

import folium
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
# %matplotlib inline

from nltk.probability import FreqDist

df=pd.read_csv('/content/naukri_data_science_jobs_india.csv')
print('Successfully read file into Dataframe...')

# concise summary of dataframe
df.info()

# shape of dataframe
print('Number of Rows: {}'.format(df.shape[0]))
print('Number of Columns: {}'.format(df.shape[1]))

# first five rows
df.head()

# user defined functions

def MinExp(txt):
    num = int(txt.split('-')[0])
    return num

def MaxExp(txt):
    num = int(txt.split('-')[1])
    return num

def preprocess_location(loc):
    loc=re.split('\(', loc)[0].strip()
    loc=re.sub('New Delhi','Delhi',loc)
    return loc

# top 10 jobs
job_10=df['Job_Role'].value_counts()[:10].rename_axis('Job Role').reset_index(name='Count')
job_10.style.background_gradient(cmap='Greys')

# plot
dataframe = pd.DataFrame()

for job in job_10['Job Role']:
    df1 = df[df['Job_Role']==job]
    skill = [skill.lower() for skills in df1['Skills/Description'] for skill in skills.split(', ') if skill != 'IT Skills']
    fdist = FreqDist(skill)
    fdist_df=pd.DataFrame(list(dict(fdist).items()), columns=['skill', 'count'])
    fdist_df= fdist_df.sort_values(by='count', ascending=False)[:10]
    fdist_df = fdist_df.assign(job=job)
    dataframe=dataframe.append(fdist_df)

    # Creating sunburst chart
fig = px.sunburst(dataframe,
                  path=['job', 'skill'],
                  values='count'
                 )

fig.update_layout(
    autosize=False,
    title_text='Top Jobs and the Required Skills',
    title_x=0.5,
    width=1080,
    height=720)

# Display the figure
fig.show()

# values in location column
df['Location'][:10]

## top 10 job locations

# splitting values and saving into a list
loc=df['Location'].tolist()
loc=[j.strip() for i in [j.strip() for i in loc for j in i.split(',')] for j in i.split('/')]

# count
fdist = FreqDist(loc)
loc_df=pd.DataFrame(list(dict(fdist).items()), columns=['location', 'job openings'])

# removing alternate names
for loc in ['Bengaluru','Secunderabad','Cochin','NCR','Gurugram']:
    loc_df=loc_df[loc_df['location']!=loc]
    
# applying function
loc_df['location']=loc_df['location'].apply(preprocess_location)
loc_df=loc_df.groupby('location').sum().reset_index(level=0)

# top 10 locations
loc_df=loc_df.sort_values(by='job openings',ascending=False)[:10]
loc_df.style.background_gradient(cmap='mako_r')

# latitude and longitude of the locations
lat=[12.9716,18.5204,17.3850,19.0760,13.0827,28.4595,28.6139,28.5355,22.5726,23.0225]
lon=[77.5946,73.8567,78.4867,72.8777,80.2707,77.0266,77.2090,77.3910,88.3639,72.5714]

df1=loc_df.copy()
df1['lat']=lat
df1['lon']=lon

# title
loc = 'Top 10 Job Locations'
title_html = '''
             <h3 align="center" style="font-size:20px"><b>{}</b></h3>
             '''.format(loc)

# creating map
m = folium.Map(location=[20,78], tiles="OpenStreetMap", zoom_start=4.5)
m.get_root().html.add_child(folium.Element(title_html))
    
for i in range(0,len(df1)):
    # marking each location
    folium.Marker(
      location=[df1.iloc[i]['lat'], df1.iloc[i]['lon']],
      popup=df1.iloc[i]['location'],
      tooltip = df1.location.values[i],
      icon=folium.Icon(icon='info-sign', color="red"),
      draggable=False
   ).add_to(m)

# Show the map
m

# Top 10 demanding skills in data science jobs
skills=[j.lower() for i in df['Skills/Description'] for j in i.split(', ')]
fdist = FreqDist(skills)
skill_df=pd.DataFrame(fdist.items(), 
                      columns=['Skill', 'Frequency']
                    ).sort_values('Frequency', ascending=False)[:10]
skill_df.style.background_gradient()

# plot

default_color = "grey"
colors = {"python": "crimson"}

color_discrete_map = {
    c: colors.get(c, default_color) 
    for c in skill_df.Skill.unique()}

fig = px.bar(skill_df, x='Frequency', y='Skill',color='Skill',orientation='h',color_discrete_map=color_discrete_map)
fig.update_layout(
    autosize=False,
    title_text='Top 10 Skills',
    title_x=0.5,
    width=900,
    height=600)

fig.show()

# number of companies available
df['Company'].nunique()

# top 10 companies
df_company=df['Company'].value_counts()[:10].rename_axis('Company').reset_index(name='Job Openings')
df_company.style.background_gradient(cmap='binary')

## Companies and Jobs

dataframe = pd.DataFrame()

for company in df_company['Company']:
    df1 = df[df['Company']==company]
    jobs = [job for job in df1['Job_Role']]
    fdist = FreqDist(jobs)
    fdist_df=pd.DataFrame(list(dict(fdist).items()), columns=['jobs', 'count'])
    fdist_df= fdist_df.sort_values(by='count', ascending=False)[:5]
    fdist_df = fdist_df.assign(company=company)
    dataframe=dataframe.append(fdist_df)
    
dataframe.head()
    
# Creating sunburst chart
fig = px.sunburst(dataframe,
                  path=['company', 'jobs'])

fig.update_layout(
    autosize=False,
    title_text='Top Job Providers and Jobs',
    title_x=0.5,
    width=1000,
    height=720)

# Display the figure
fig.show()

# top 10 values in 'Job Experience'
df['Job Experience'].value_counts()[:10]

# outliers in 'Job Experience' column
lst=[]
for i in df['Job Experience']:
    c=False
    for j in i:
        if j.isalpha():
            c=True
    if c==True:
        lst.append(i)
        
lst

# removing outliers
for j in lst:
    df=df[df['Job Experience'] != j]

# new features
df['Min. Exp.'] = df['Job Experience'].apply(MinExp)
df['Max. Exp.'] = df['Job Experience'].apply(MaxExp)

# plot - Job Experience Demanded in Data Science Roles in India

fig = plt.figure(figsize=(14, 7), dpi=123, facecolor='#e4e5e9')
spec = fig.add_gridspec(ncols=6, nrows=2)

ax0 = fig.add_subplot(spec[0, :4])
sns.countplot(x='Min. Exp.',data=df, color='#657ffb', edgecolor='black')
plt.ylabel("Job Count", fontsize=11)
plt.xlabel('Minimum Experience', fontsize=11)
plt.xlim(0,20)
plt.ylim(0,2400)

ax1 = fig.add_subplot(spec[1, :4])
sns.countplot(x='Max. Exp.',data=df, color='#bad2ef',  edgecolor='black')
plt.ylabel("Job Count", fontsize=11)
plt.xlabel('Maximum Experience', fontsize=11)
plt.ylim(0,2400)
# plt.xlim(0,20)

ax2 = fig.add_subplot(spec[:, 4])
sns.boxplot(y=df['Min. Exp.'], color='#657ffb')
plt.xlabel('Minimum Experience',labelpad=5, fontsize=10)
plt.ylim(0,31)
plt.ylabel('')

ax3 = fig.add_subplot(spec[:, 5])
sns.boxplot(y=df['Max. Exp.'], color='#BAD2EF')
plt.xlabel('Maximum Experience',labelpad=5, fontsize=10)
plt.ylabel('')
plt.ylim(0,31)

for ax in [ax0,ax1,ax2,ax3]:
    ax.patch.set_alpha(0.0)
    ax.spines['top'].set_visible(False)
    ax.spines['right'].set_visible(False)

fig.suptitle('Job Experience Demanded in Data Science Roles in India', fontsize=17, y=1)
plt.show()

# Average Minimum Job Experience Required Top Jobs
job_list = df['Job_Role'].value_counts().iloc[:10].index.tolist()  
exp = [round(df[df['Job_Role']==job]['Min. Exp.'].mean(),2) for job in job_list]

df_job=pd.DataFrame({'Jobs':job_list, 'Average Min. Exp':exp})
df_job=df_job.sort_values('Average Min. Exp', ascending=False)
df_job

# job with highest requirement of minimum experience
df[df['Min. Exp.']==df['Min. Exp.'].max()]

